{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-15T15:04:36.690893Z",
     "iopub.status.busy": "2024-11-15T15:04:36.689959Z",
     "iopub.status.idle": "2024-11-15T15:04:52.703274Z",
     "shell.execute_reply": "2024-11-15T15:04:52.702459Z",
     "shell.execute_reply.started": "2024-11-15T15:04:36.690840Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947e3ecbf84a4a7c97dcca05fe7c4816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/479 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5a208b15894a47bb019ea29c97eaad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00002.parquet:   0%|          | 0.00/98.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c44f310691b44d6baf9f6fae1405ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00002.parquet:   0%|          | 0.00/98.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22789769cb64cde99263cfce5bcc110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/18.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8489ac5afc4e65bf8d07293e6253b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/109101 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e17cd40ce0b9485496a5870c9329063b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoConfig\n",
    "from huggingface_hub import login\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, classification_report\n",
    "import os\n",
    "\n",
    "# Load the dataset with embeddings and scores\n",
    "dataset = load_dataset(\"daparasyte/gpt4_dataset_prompt_scores_with_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T15:04:52.705375Z",
     "iopub.status.busy": "2024-11-15T15:04:52.704907Z",
     "iopub.status.idle": "2024-11-15T15:04:52.711450Z",
     "shell.execute_reply": "2024-11-15T15:04:52.710629Z",
     "shell.execute_reply.started": "2024-11-15T15:04:52.705340Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"]\n",
    "val_dataset = dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T15:04:52.712781Z",
     "iopub.status.busy": "2024-11-15T15:04:52.712505Z",
     "iopub.status.idle": "2024-11-15T15:06:28.549138Z",
     "shell.execute_reply": "2024-11-15T15:06:28.548067Z",
     "shell.execute_reply.started": "2024-11-15T15:04:52.712750Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prepare DataLoader for balanced training data\n",
    "train_embeddings = torch.tensor(train_dataset[\"embedding\"], dtype=torch.float32)\n",
    "train_scores = torch.tensor(train_dataset[\"score\"], dtype=torch.long) - 1  # Zero-indexing the classes for PyTorch\n",
    "val_embeddings = torch.tensor(val_dataset[\"embedding\"], dtype=torch.float32)\n",
    "val_scores = torch.tensor(val_dataset[\"score\"], dtype=torch.long) - 1  # Zero-indexing the classes\n",
    "\n",
    "# Define DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(TensorDataset(train_embeddings, train_scores), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(val_embeddings, val_scores), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T15:06:28.551578Z",
     "iopub.status.busy": "2024-11-15T15:06:28.551231Z",
     "iopub.status.idle": "2024-11-15T15:06:28.570799Z",
     "shell.execute_reply": "2024-11-15T15:06:28.569834Z",
     "shell.execute_reply.started": "2024-11-15T15:06:28.551544Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train embeddings shape: torch.Size([109101, 1024])\n",
      "Train scores min: 0, max: 4\n",
      "Validation embeddings shape: torch.Size([10000, 1024])\n",
      "Validation scores min: 0, max: 4\n"
     ]
    }
   ],
   "source": [
    "# Print shapes and label range for debugging\n",
    "print(f\"Train embeddings shape: {train_embeddings.shape}\")\n",
    "print(f\"Train scores min: {train_scores.min()}, max: {train_scores.max()}\")\n",
    "print(f\"Validation embeddings shape: {val_embeddings.shape}\")\n",
    "print(f\"Validation scores min: {val_scores.min()}, max: {val_scores.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T15:06:28.572150Z",
     "iopub.status.busy": "2024-11-15T15:06:28.571849Z",
     "iopub.status.idle": "2024-11-15T15:06:29.815256Z",
     "shell.execute_reply": "2024-11-15T15:06:29.814244Z",
     "shell.execute_reply.started": "2024-11-15T15:06:28.572117Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "# Import Transformer layers\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import numpy as np\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=256, output_dim=5, nhead=8, nlayers=5, dropout_rate=0.5):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        \n",
    "        # Define Transformer Encoder\n",
    "        encoder_layers = TransformerEncoderLayer(d_model=input_dim, nhead=nhead, dim_feedforward=hidden_dim, dropout=dropout_rate)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers=nlayers)\n",
    "        \n",
    "        # Fully connected layers with dropout\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)  # Add dropout\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer_encoder(x.unsqueeze(1))  # Add sequence dimension\n",
    "        x = torch.relu(self.fc1(x[:, -1, :]))  # Use last token\n",
    "        x = self.dropout(x)  # Apply dropout after the first FC layer\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "# Initialize model, criterion, optimizer, etc.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "input_dim = train_embeddings.shape[1]\n",
    "model = TransformerClassifier(input_dim=input_dim).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-5)\n",
    "\n",
    "\n",
    "# class PromptScoreClassifier(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim=128, output_dim=5):\n",
    "#         super(PromptScoreClassifier, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.dropout = nn.Dropout(0.3)\n",
    "#         self.fc2 = nn.Linear(hidden_dim, output_dim)  # Output layer for 5 classes\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.relu(self.fc1(x))\n",
    "#         x = self.dropout(x)\n",
    "#         return self.fc2(x)  # Logits for each class\n",
    "\n",
    "# # Initialize model, criterion, optimizer, etc.\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model = PromptScoreClassifier(input_dim=train_embeddings.shape[1]).to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T15:06:29.817348Z",
     "iopub.status.busy": "2024-11-15T15:06:29.816671Z",
     "iopub.status.idle": "2024-11-15T15:06:29.824531Z",
     "shell.execute_reply": "2024-11-15T15:06:29.823461Z",
     "shell.execute_reply.started": "2024-11-15T15:06:29.817297Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "Number of Transformer layers: 5\n",
      "Number of heads: 8\n",
      "Total parameters: 23904005\n"
     ]
    }
   ],
   "source": [
    "# Model summary\n",
    "print(\"Model Summary:\")\n",
    "print(f\"Number of Transformer layers: {model.transformer_encoder.num_layers}\")\n",
    "print(f\"Number of heads: {model.transformer_encoder.layers[0].self_attn.num_heads}\")\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T13:51:53.234848Z",
     "iopub.status.busy": "2024-11-15T13:51:53.234259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, classification_report\n",
    "\n",
    "# Define the training loop\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-5,\n",
    "    num_epochs=50,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    # Initialize optimizer and loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "    progress_bar = tqdm(total=num_epochs)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss_sum = 0.0\n",
    "        n = 0\n",
    "        for embeddings, scores in train_loader:\n",
    "            embeddings, scores = embeddings.to(device), scores.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(embeddings)\n",
    "            loss = criterion(outputs, scores)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_sum += loss.item() * embeddings.size(0)\n",
    "            n += embeddings.size(0)\n",
    "\n",
    "        avg_train_loss = train_loss_sum / n\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss_sum = 0.0\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for embeddings, scores in val_loader:\n",
    "                embeddings, scores = embeddings.to(device), scores.to(device)\n",
    "                outputs = model(embeddings)\n",
    "                val_loss = criterion(outputs, scores)\n",
    "                val_loss_sum += val_loss.item() * embeddings.size(0)\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_preds.extend(predicted.cpu().numpy())\n",
    "                val_labels.extend(scores.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = val_loss_sum / len(val_loader.dataset)\n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_mae = mean_absolute_error(val_labels, val_preds)\n",
    "\n",
    "        # Print epoch results\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "              f\"Validation Loss: {avg_val_loss:.4f}, \"\n",
    "              f\"Validation Accuracy: {val_accuracy:.4f}, \"\n",
    "              f\"Validation MAE: {val_mae:.4f}\")\n",
    "\n",
    "        # Check for best validation accuracy\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), \"best_model.pt\")  # Save best model\n",
    "\n",
    "        progress_bar.set_postfix(train_loss=avg_train_loss, val_loss=avg_val_loss, val_acc=val_accuracy)\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-5,\n",
    "    num_epochs=50,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T15:06:29.827046Z",
     "iopub.status.busy": "2024-11-15T15:06:29.826060Z",
     "iopub.status.idle": "2024-11-15T15:06:31.152493Z",
     "shell.execute_reply": "2024-11-15T15:06:31.151552Z",
     "shell.execute_reply.started": "2024-11-15T15:06:29.827008Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/4096559140.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"/kaggle/input/router-training/best_model.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded for final evaluation.\n"
     ]
    }
   ],
   "source": [
    "# Load the best model for evaluation\n",
    "# model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "model.load_state_dict(torch.load(\"/kaggle/input/router-training/best_model.pt\"))\n",
    "model.eval()\n",
    "print(\"Best model loaded for final evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T15:08:50.355897Z",
     "iopub.status.busy": "2024-11-15T15:08:50.355487Z",
     "iopub.status.idle": "2024-11-15T15:08:55.468370Z",
     "shell.execute_reply": "2024-11-15T15:08:55.467263Z",
     "shell.execute_reply.started": "2024-11-15T15:08:50.355862Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e2d5016ec341598cab0f3f6f408a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/95.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to Hugging Face Hub successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "from huggingface_hub import HfApi, Repository\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Save the model's state dictionary\n",
    "save_directory = \"/kaggle/working/prompt_complexity_classifier_1\"\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "torch.save(model.state_dict(), os.path.join(save_directory, \"pytorch_model.bin\"))\n",
    "\n",
    "# Save the config\n",
    "config = AutoConfig.from_pretrained(\"jinaai/jina-embeddings-v3\", trust_remote_code=True)\n",
    "config.num_labels = 5  # Since we are scoring from 1 to 5\n",
    "config.save_pretrained(save_directory)\n",
    "\n",
    "# # Create a model card with simple information about the model\n",
    "# with open(os.path.join(save_directory, \"README.md\"), \"w\") as f:\n",
    "#     f.write(\"# Prompt Complexity Classifier\\nThis model scores prompts based on complexity from 1 to 5.\")\n",
    "\n",
    "# Push the directory to the Hub\n",
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "repo_id = \"daparasyte/prompt_complexity_classifier_1\"  # Replace with your username/repo name\n",
    "\n",
    "# Authenticate\n",
    "from huggingface_hub import login\n",
    "login(token=\"hf_api_key\")  # Replace with your Hugging Face API key\n",
    "\n",
    "# Upload the model directory\n",
    "api.upload_folder(\n",
    "    folder_path=save_directory,\n",
    "    path_in_repo=\".\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"model\"\n",
    ")\n",
    "\n",
    "print(\"Model pushed to Hugging Face Hub successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 207570481,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
